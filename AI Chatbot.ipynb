{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\nps_chat.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The NLTK Downloads we need\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golobal Constants\n",
    "GREETING_INPUTS = (\"hello\", \"hi\")\n",
    "GREETING_RESPONCES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"Talkin' to me?\"]\n",
    "FILE_NAME = \"canada_faq.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "lem = nltk.stem.WordNetLemmatizer()\n",
    "remove_punctuation = dict((ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_features(chat):\n",
    "    # fetch_features() transforms a chat into a classifier friendly format\n",
    "    \n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(chat):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise(tokens):\n",
    "    # This method performs the lemmatization on the words\n",
    "    return [lem.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    # This method tokenizes the words\n",
    "    return lemmatise(nltk.word_tokenize(text.lower().translate(remove_punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(sentence):\n",
    "    # This method responces with a standard a bot recognizes\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(user_response):\n",
    "    resp      =''\n",
    "    q_list.append(user_response)\n",
    "    TfidfVec  = TfidfVectorizer(tokenizer=tokenise, stop_words='english')\n",
    "    tfidf     = TfidfVec.fit_transform(q_list)\n",
    "    vals      = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx       = vals.argsort()[0][-2]\n",
    "    flat      = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        resp = resp+\"Sorry! I don't know the answer to this. Would you like to try again? Type Ciao to exit\"\n",
    "        return resp\n",
    "    else:\n",
    "        resp_ids = qa_dict[idx]\n",
    "        resp_str = ''\n",
    "        s_id = resp_ids[0]\n",
    "        end = resp_ids[1]\n",
    "        while s_id<end :\n",
    "            resp_str = resp_str + \" \" + sent_tokens[s_id]\n",
    "            s_id+=1\n",
    "        resp = resp+resp_str\n",
    "        return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the classifier\n",
    "\n",
    "# Fetching the chat corpus\n",
    "chats = nltk.corpus.nps_chat.xml_posts()[:10000]\n",
    "\n",
    "# Extract the features from chat\n",
    "featuresets = [(fetch_features(chat.text), chat.get('class')) for chat in chats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into test and train sets\n",
    "size = int(len(featuresets) * 0.1) # 10%\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]  # 90 training and 10 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -2.70805        0.050\n",
      "             2          -1.25314        0.847\n",
      "             3          -0.92168        0.881\n",
      "             4          -0.75008        0.898\n",
      "             5          -0.63707        0.910\n",
      "             6          -0.55432        0.918\n",
      "             7          -0.49069        0.924\n",
      "             8          -0.44076        0.929\n",
      "             9          -0.40122        0.932\n",
      "            10          -0.36960        0.936\n",
      "            11          -0.34394        0.940\n",
      "            12          -0.32270        0.944\n",
      "            13          -0.30477        0.946\n",
      "            14          -0.28939        0.948\n",
      "            15          -0.27600        0.950\n",
      "            16          -0.26421        0.952\n",
      "            17          -0.25371        0.953\n",
      "            18          -0.24430        0.954\n",
      "            19          -0.23580        0.956\n",
      "            20          -0.22806        0.957\n",
      "            21          -0.22099        0.958\n",
      "            22          -0.21450        0.959\n",
      "            23          -0.20850        0.960\n",
      "            24          -0.20295        0.961\n",
      "            25          -0.19778        0.961\n",
      "            26          -0.19297        0.962\n",
      "            27          -0.18846        0.962\n",
      "            28          -0.18423        0.963\n",
      "            29          -0.18026        0.963\n",
      "            30          -0.17651        0.964\n",
      "            31          -0.17297        0.965\n",
      "            32          -0.16963        0.965\n",
      "            33          -0.16645        0.965\n",
      "            34          -0.16343        0.966\n",
      "            35          -0.16056        0.966\n",
      "            36          -0.15783        0.966\n",
      "            37          -0.15522        0.967\n",
      "            38          -0.15273        0.968\n",
      "            39          -0.15034        0.968\n",
      "            40          -0.14806        0.968\n",
      "            41          -0.14587        0.969\n",
      "            42          -0.14377        0.969\n",
      "            43          -0.14175        0.969\n",
      "            44          -0.13981        0.969\n",
      "            45          -0.13794        0.970\n",
      "            46          -0.13614        0.970\n",
      "            47          -0.13440        0.970\n",
      "            48          -0.13273        0.971\n",
      "            49          -0.13111        0.971\n",
      "            50          -0.12954        0.971\n",
      "            51          -0.12803        0.971\n",
      "            52          -0.12657        0.972\n",
      "            53          -0.12515        0.972\n",
      "            54          -0.12378        0.972\n",
      "            55          -0.12244        0.972\n",
      "            56          -0.12115        0.973\n",
      "            57          -0.11990        0.973\n",
      "            58          -0.11868        0.974\n",
      "            59          -0.11750        0.974\n",
      "            60          -0.11635        0.974\n",
      "            61          -0.11523        0.974\n",
      "            62          -0.11414        0.975\n",
      "            63          -0.11308        0.975\n",
      "            64          -0.11205        0.975\n",
      "            65          -0.11104        0.975\n",
      "            66          -0.11006        0.975\n",
      "            67          -0.10910        0.976\n",
      "            68          -0.10817        0.976\n",
      "            69          -0.10726        0.976\n",
      "            70          -0.10637        0.976\n",
      "            71          -0.10550        0.976\n",
      "            72          -0.10466        0.977\n",
      "            73          -0.10383        0.977\n",
      "            74          -0.10302        0.977\n",
      "            75          -0.10222        0.977\n",
      "            76          -0.10145        0.977\n",
      "            77          -0.10069        0.977\n",
      "            78          -0.09995        0.977\n",
      "            79          -0.09922        0.977\n",
      "            80          -0.09851        0.977\n",
      "            81          -0.09782        0.977\n",
      "            82          -0.09714        0.977\n",
      "            83          -0.09647        0.977\n",
      "            84          -0.09581        0.978\n",
      "            85          -0.09517        0.978\n",
      "            86          -0.09454        0.978\n",
      "            87          -0.09392        0.978\n",
      "            88          -0.09331        0.978\n",
      "            89          -0.09272        0.978\n",
      "            90          -0.09213        0.978\n",
      "            91          -0.09156        0.978\n",
      "            92          -0.09100        0.978\n",
      "            93          -0.09044        0.978\n",
      "            94          -0.08990        0.978\n",
      "            95          -0.08937        0.978\n",
      "            96          -0.08884        0.978\n",
      "            97          -0.08833        0.978\n",
      "            98          -0.08782        0.978\n",
      "            99          -0.08732        0.978\n",
      "         Final          -0.08683        0.978\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.MaxentClassifier.train(train_set)\n",
    "# for NaiveBayesClassifier\n",
    "#classifier = nltk.NaiveBayesClassifier.train(train_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # for saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MaxentClassifier.sav']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "classifier_file_name = 'MaxentClassifier.sav'\n",
    "joblib.dump(classifier, classifier_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "load_classifier = joblib.load(classifier_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy final one\n",
    "print(nltk.classify.accuracy(load_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Bank Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_bank = open(FILE_NAME, 'r', errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_text = ques_bank.read()\n",
    "qb_text = qb_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(qb_text) # Converts the list into sentences\n",
    "word_tokens = nltk.word_tokenize(qb_text) # converts the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict     = {} #The Dictionary to store questions and corresponding answers\n",
    "q_list      = [] #List of all questions\n",
    "s_count     = 0  #Sentence counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract questions and answers\n",
    "#Answer is all the content between 2 questions [assumption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "while s_count < len(sent_tokens):\n",
    "    result = load_classifier.classify(fetch_features(sent_tokens[s_count]))\n",
    "    if(\"question\" in result.lower()):\n",
    "        next_question_id = s_count+1\n",
    "        next_question = load_classifier.classify(fetch_features(sent_tokens[next_question_id]))\n",
    "        \n",
    "        while(not(\"question\" in next_question.lower()) and next_question_id < len(sent_tokens) - 1):\n",
    "            next_question_id += 1\n",
    "            next_question = load_classifier.classify(fetch_features(sent_tokens[next_question_id]))\n",
    "        \n",
    "        q_list.append(sent_tokens[s_count])\n",
    "        end = next_question_id\n",
    "        \n",
    "        if((next_question_id - s_count) > 5):\n",
    "            end = s_count+5\n",
    "        \n",
    "        qa_dict.update({len(q_list)-1:[s_count+1, end]})\n",
    "        s_count = next_question_id\n",
    "    \n",
    "    else: \n",
    "        s_count += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responce Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mNEO: \n",
      "I'm a Neo, I have all the answers, if you want to exit, type Ciao\u001b[0m\n",
      "\u001b[1m\u001b[31m\n",
      "YOU: \u001b[0m\n",
      "What is application process?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "NEO:\u001b[0m\n",
      "\u001b[34mWe consider your application non-routine if:\n",
      "\n",
      "you asked to change your personal information, such as:\n",
      "name\n",
      "sex designation\n",
      "date of birth\n",
      "you missed a:\n",
      "test\n",
      "interview\n",
      "hearing\n",
      "we need you to submit extra documents, like:\n",
      "fingerprints\n",
      "residence documents\n",
      "we asked you to come to another interview or hearing after you attended your interview\n",
      "we also consider your citizenship application non-routine if you:\n",
      "\n",
      "failed a test\n",
      "didnâ€™t meet the language requirements during your interview\n",
      "for more information\n",
      "how are ircc processing times calculated?\u001b[0m\n",
      "\u001b[1m\u001b[31m\n",
      "YOU: \u001b[0m\n",
      "Okay so what should I do now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "NEO:\u001b[0m\n",
      "\u001b[34mSorry! i don't know the answer to this. would you like to try again? type ciao to exit\u001b[0m\n",
      "\u001b[1m\u001b[31m\n",
      "YOU: \u001b[0m\n",
      "Okay, what is your name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "NEO:\u001b[0m\n",
      "\u001b[34mSorry! i don't know the answer to this. would you like to try again? type ciao to exit\u001b[0m\n",
      "\u001b[1m\u001b[31m\n",
      "YOU: \u001b[0m\n",
      "how are ircc processing times calculated?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "NEO:\u001b[0m\n",
      "\u001b[34mTo check the status of your application, you can:\n",
      "\n",
      "step 1: check the processing times. step 2: check the status of your application online through the client application status service. step 3: if normal processing time for your application has passed, you may contact the call centre to verify the status of your application. find out more about improvements to our processing times and reducing the backlog.\u001b[0m\n",
      "\u001b[1m\u001b[31m\n",
      "YOU: \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(colored(\"NEO: \\nI'm a Mona, I have all the answers, if you want to exit, type Ciao\", 'blue', attrs=['bold']))\n",
    "while(flag == True):\n",
    "    print(colored(\"\\nYOU: \",'red', attrs=['bold']))\n",
    "    u_input = input()\n",
    "    u_input = u_input.lower()\n",
    "    \n",
    "    if(u_input!= 'ciao'):\n",
    "        if(greet(u_input)!=None):\n",
    "            print(colored(\"\\nNEO:\",'blue',attrs=['bold']))\n",
    "            print(greet(u_input))\n",
    "        \n",
    "        else: \n",
    "            print(colored(\"\\nNEO:\",'blue',attrs=['bold']))\n",
    "            print(colored(match(u_input).strip().capitalize(),'blue'))\n",
    "            q_list.remove(u_input)\n",
    "    \n",
    "    else:\n",
    "        flag=False\n",
    "        print(colored(\"\\nNEO: Bye! take care..\",'blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
